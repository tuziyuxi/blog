---
title: 如何理解HDFS的流式数据访问模式
date: 2019-08-23 10:10:49
categories:
- 大数据
tags:
- 大数据
- HDFS
- 流式数据访问
---

HDFS的设计目标：以流式数据访问模式存储超大文件，运行在商业集群上
1）存储超大文件
2) 流式数据访问，一次写入，多次读写
3）商业硬件

上述的流式数据访问，和Spark Stream、Apache Storm中的流式数据不一样，前者是一种访问磁盘文件的方式（流失数据访问 vs 随机数据访问），后者是一种大数据的处理框架（批处理 vs 流处理）


1）流式数据访问：最小化磁盘的寻址开销，只需要寻址一次，然后一直读下去，适合一次写，多次读的数据访问
2）随机数据访问：要求定位、查询或修改数据的延迟较小，传统关系型数据库符合这一点